"""ê´€ê³„ ê·¸ë˜í”„ ìƒì„± ëª¨ë“ˆ"""
import json
import time
from typing import List, Dict, Any
from .ai_service import call_ai_api


def extract_character_relationships_with_ai(keyword: str, all_documents: List[Dict[str, Any]], model: str = "gpt-4o-mini") -> Dict[str, Any]:
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¬¸ì„œì—ì„œ ì¸ë¬¼ ê´€ê³„ ê·¸ë˜í”„ ì¶”ì¶œ
    
    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        all_documents: ëª¨ë“  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (ê°ê° title, text, image_src í¬í•¨)
        model: ì‚¬ìš©í•  AI ëª¨ë¸ (gpt-4o-mini ë˜ëŠ” gpt-5)
    
    Returns:
        ê´€ê³„ ê·¸ë˜í”„ ë°ì´í„° (JSON í˜•íƒœ)
    """
    print("\nğŸ¤– AIì—ê²Œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± ìš”ì²­ ì¤‘...")
    start_time = time.time()
    
    # ì¸ë¬¼ëª… -> ì´ë¯¸ì§€ URL ë§¤í•‘ ìƒì„± (fallbackìš©)
    character_to_image_urls = {}
    for doc in all_documents:
        title = doc.get('title', '')
        image_urls = doc.get('image_urls', [])
        if title and image_urls:
            # ì œëª©ì—ì„œ ê´„í˜¸ë‚˜ ìŠ¬ë˜ì‹œ ì œê±°í•œ ë²„ì „ë„ ë§¤í•‘
            clean_title = title.split('(')[0].split('/')[0].strip()
            # ì‹¤ì œ URLë§Œ í•„í„°ë§ (íŒŒì¼ëª… í˜•ì‹ ì œì™¸)
            real_urls = [img.get('url') if isinstance(img, dict) else img for img in image_urls if (img.get('url') if isinstance(img, dict) else img).startswith('http')]
            if real_urls:
                character_to_image_urls[clean_title] = real_urls
                character_to_image_urls[title] = real_urls
    
    # ëª¨ë“  ë¬¸ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ëª©ë¡ í•©ì¹˜ê¸° (ìµœì í™”: í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ)
    combined_text = ""
    for doc in all_documents:
        title = doc.get('title', 'Unknown')
        text = doc.get('text', '')[:3000]  # ê° ë¬¸ì„œë‹¹ ìµœëŒ€ 3000ìë¡œ ë‹¨ì¶• (5000 -> 3000)
        image_urls = doc.get('image_urls', [])
        
        combined_text += f"\n\n=== {title} ===\n"
        
        # ì´ë¯¸ì§€ URL ëª©ë¡ ì¶”ê°€ (AIê°€ ì¸ë¬¼ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ë„ë¡)
        if image_urls:
            combined_text += f"\n[ì´ ë¬¸ì„œì˜ ì´ë¯¸ì§€ ëª©ë¡ - ì¸ë¬¼ '{title}'ì™€ ê´€ë ¨ëœ ì´ë¯¸ì§€]\n"
            # ì‹¤ì œ URLë§Œ ìš°ì„  í‘œì‹œ
            real_urls = [img for img in image_urls if (img.get('url') if isinstance(img, dict) else img).startswith('http')]
            
            for idx, img_info in enumerate(real_urls[:3], 1):  # ìµœëŒ€ 3ê°œë¡œ ë‹¨ì¶• (5 -> 3)
                if isinstance(img_info, dict):
                    url = img_info.get('url', '')
                    alt = img_info.get('alt', '')
                else:
                    url = img_info
                    alt = ''
                
                img_text = f"{idx}. {url}"
                if alt:
                    img_text += f" (alt: {alt})"
                combined_text += img_text + "\n"
            
            if len(real_urls) > 3:
                combined_text += f"... ì™¸ {len(real_urls) - 3}ê°œ ì´ë¯¸ì§€ ë” ìˆìŒ\n"
            combined_text += "\n"
        
        combined_text += text
    
    # ì¸ë¬¼ ë¬¸ì„œ ì œëª© ì¶”ì¶œ (AIì—ê²Œ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬)
    character_doc_titles = []
    for doc in all_documents:
        if doc.get('type') == 'character':
            title = doc.get('title', '')
            if title:
                character_doc_titles.append(title)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸° (15000ìë¡œ ë‹¨ì¶•)
    if len(combined_text) > 15000:
        combined_text = combined_text[:15000] + "\n\n... (ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ ìƒëµ) ..."
    
    character_list_text = ""
    if character_doc_titles:
        character_list_text = f"\n\nì¤‘ìš”: ìœ„ ë¬¸ì„œë“¤ ì¤‘ ë‹¤ìŒ {len(character_doc_titles)}ëª…ì˜ ì¸ë¬¼ë“¤ì˜ ë¬¸ì„œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n"
        for i, title in enumerate(character_doc_titles, 1):
            character_list_text += f"{i}. {title}\n"
        character_list_text += f"\nì´ {len(character_doc_titles)}ëª…ì˜ ì¸ë¬¼ë“¤ì€ ë°˜ë“œì‹œ ê·¸ë˜í”„ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ë¬¸ì„œì—ì„œ ì–¸ê¸‰ëœ ë‹¤ë¥¸ ì£¼ìš” ì¸ë¬¼ë“¤ë„ ì¶”ê°€í•˜ì—¬ ìµœì†Œ {len(character_doc_titles) + 5}ëª… ì´ìƒì˜ ì¸ë¬¼ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\n"
    
    prompt = f"""ë‹¤ìŒì€ "{keyword}"ì— ëŒ€í•œ ë‚˜ë¬´ìœ„í‚¤ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì…ë‹ˆë‹¤.

{combined_text}{character_list_text}

ìœ„ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ì—¬ ë“±ì¥í•˜ëŠ” ì¸ë¬¼ë“¤ì˜ ê´€ê³„ë¥¼ ê·¸ë˜í”„ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1. ê° ì¸ë¬¼ì˜ ì´ë¦„, ì´ë¯¸ì§€ src (ìˆìœ¼ë©´), ê¸°ë³¸ ì„¤ëª…ì„ í¬í•¨
   - ê° ë¬¸ì„œì˜ [ì´ ë¬¸ì„œì˜ ì´ë¯¸ì§€ ëª©ë¡] ì„¹ì…˜ì„ ì°¸ê³ í•˜ì—¬, í•´ë‹¹ ì¸ë¬¼ê³¼ ê°€ì¥ ê´€ë ¨ì´ ìˆëŠ” ì´ë¯¸ì§€ì˜ srcë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”
   - ì£¼ë³€ í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì¸ë¬¼ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€ë¥¼ íŒë‹¨í•˜ì„¸ìš”
   - ì¸ë¬¼ì˜ ì–¼êµ´ì´ë‚˜ ì „ì²´ ëª¨ìŠµì„ ë³´ì—¬ì£¼ëŠ” ì´ë¯¸ì§€ë¥¼ ìš°ì„  ì„ íƒí•˜ì„¸ìš”
   - ë¡œê³ , ì•„ì´ì½˜, ë°°ê²½ ì´ë¯¸ì§€ ë“±ì€ ì œì™¸í•˜ì„¸ìš”
   - ë°˜ë“œì‹œ https://ë¡œ ì‹œì‘í•˜ëŠ” ì‹¤ì œ ì´ë¯¸ì§€ URLë§Œ ì„ íƒí•˜ì„¸ìš”
   - í•´ë‹¹ ì¸ë¬¼ ë¬¸ì„œì— ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ nullë¡œ ì„¤ì •í•˜ì„¸ìš”
2. ì¸ë¬¼ ê°„ì˜ ê´€ê³„ë¥¼ ê°„ì„ (edge)ìœ¼ë¡œ í‘œí˜„
   - ì œê³µëœ ì¸ë¬¼ ë¬¸ì„œì˜ ì¸ë¬¼ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨í•˜ì„¸ìš”
   - ë¬¸ì„œì—ì„œ ì–¸ê¸‰ëœ ë‹¤ë¥¸ ì£¼ìš” ì¸ë¬¼ë“¤ë„ ì¶”ê°€í•˜ê³  ê´€ê³„ë¥¼ ì„¤ì •í•˜ì„¸ìš”
3. ê° ê°„ì„ ì—ëŠ” ê´€ê³„ ì„¤ëª…ì„ ìƒì„¸í•˜ê²Œ í¬í•¨ (ìµœì†Œ 10ì ì´ìƒ, ìµœëŒ€ 30ì ì •ë„)
   - ë‹¨ìˆœíˆ "ì¹œêµ¬", "ì " ê°™ì€ í•œ ë‹¨ì–´ê°€ ì•„ë‹Œ êµ¬ì²´ì ì¸ ì„¤ëª…
   - ì˜ˆ: "ì§ì‚¬ë‘í•¨" â†’ "ì§ì‚¬ë‘í•˜ëŠ” ê´€ê³„", "ì¹œêµ¬" â†’ "ì ˆì¹œí•œ ì¹œêµ¬ ê´€ê³„", "ì " â†’ "ì ëŒ€ì ì¸ ê´€ê³„", "í˜•ì œ" â†’ "í˜ˆì—° ê´€ê³„ì¸ í˜•ì œ"
   - ê°€ëŠ¥í•˜ë©´ ê´€ê³„ì˜ ë§¥ë½ì´ë‚˜ ë°°ê²½ì„ í¬í•¨ (ì˜ˆ: "ê³¼ê±° ë™ë£Œì˜€ë˜ ì ëŒ€ ê´€ê³„", "ì„œë¡œë¥¼ ì¡´ê²½í•˜ëŠ” ë¼ì´ë²Œ ê´€ê³„")
4. ë°©í–¥ì„±ì´ ìˆëŠ” ê´€ê³„ëŠ” í™”ì‚´í‘œë¡œ í‘œí˜„ (A -> B: Aê°€ Bì—ê²Œ ê´€ê³„)
5. ì œê³µëœ ì¸ë¬¼ ë¬¸ì„œì˜ ì¸ë¬¼ë“¤ì„ ëª¨ë‘ í¬í•¨í•˜ê³ , ë¬¸ì„œì—ì„œ ì–¸ê¸‰ëœ ë‹¤ë¥¸ ì£¼ìš” ì¸ë¬¼ë“¤ë„ ì¶”ê°€í•˜ì—¬ ìµœì†Œí•œ ì œê³µëœ ì¸ë¬¼ ìˆ˜ë³´ë‹¤ ë” ë§ì€ ì¸ë¬¼ì„ í¬í•¨í•˜ì„¸ìš”
6. JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”

ì‘ë‹µ í˜•ì‹:
{{
  "characters": [
    {{
      "name": "ì¸ë¬¼ëª…",
      "image_src": "ì´ë¯¸ì§€ê²½ë¡œ ë˜ëŠ” null",
      "description": "ê¸°ë³¸ ì„¤ëª…"
    }}
  ],
  "relationships": [
    {{
      "from": "ì¸ë¬¼A",
      "to": "ì¸ë¬¼B",
      "relation": "ê´€ê³„ ì„¤ëª…"
    }}
  ]
}}

ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ê³  JSONë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ë‚˜ë¬´ìœ„í‚¤ ë¬¸ì„œì—ì„œ ì¸ë¬¼ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
        {"role": "user", "content": prompt}
    ]
    
    try:
        response = call_ai_api(messages, model=model, temperature=0.5)
        # JSON íŒŒì‹±
        response = response.strip()
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if response.startswith("```json"):
            lines = response.split("\n")
            response = "\n".join(lines[1:-1]) if len(lines) > 2 else response
        elif response.startswith("```"):
            lines = response.split("\n")
            response = "\n".join(lines[1:-1]) if len(lines) > 2 else response
        
        # JSON ê°ì²´ ì°¾ê¸° (ì¤‘ê´„í˜¸ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„)
        json_start = response.find('{')
        json_end = response.rfind('}') + 1
        if json_start != -1 and json_end > json_start:
            response = response[json_start:json_end]
        
        graph_data = json.loads(response)
        
        # AI ì‘ë‹µ í›„ ì´ë¯¸ì§€ URL ë³´ì • ë° fallback
        fixed_count = 0
        fallback_count = 0
        for char_node in graph_data.get('characters', []):
            name = char_node.get('name', '')
            ai_selected_image = char_node.get('image_src')
            
            if name:
                # 1. AIê°€ ì„ íƒí•œ ì´ë¯¸ì§€ê°€ íŒŒì¼ëª… í˜•ì‹ì´ë©´ nullë¡œ ì„¤ì •
                if ai_selected_image and not ai_selected_image.startswith('http'):
                    char_node['image_src'] = None
                
                # 2. AIê°€ nullì´ê±°ë‚˜ ì„ íƒí•˜ì§€ ëª»í•œ ê²½ìš°, ì‹¤ì œ ë¬¸ì„œì—ì„œ ê°€ì ¸ì˜¨ ì´ë¯¸ì§€ ì‚¬ìš© (fallback)
                if not char_node.get('image_src') or char_node.get('image_src') == 'null' or char_node.get('image_src') == '':
                    if name in character_to_image_urls:
                        image_list = character_to_image_urls[name]
                        # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì„ íƒ
                        char_node['image_src'] = image_list[0] if image_list else None
                        if image_list:
                            fallback_count += 1
                    else:
                        clean_name = name.split('(')[0].split('/')[0].strip()
                        if clean_name in character_to_image_urls:
                            image_list = character_to_image_urls[clean_name]
                            # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì„ íƒ
                            char_node['image_src'] = image_list[0] if image_list else None
                            if image_list:
                                fallback_count += 1
                        else:
                            char_node['image_src'] = None
        
        if fallback_count > 0:
            print(f"   - ì´ë¯¸ì§€ fallback: {fallback_count}ê°œ ì¸ë¬¼ì— ì´ë¯¸ì§€ ì¶”ê°€")
        
        elapsed_time = time.time() - start_time
        print(f"âœ… AIê°€ ê´€ê³„ ê·¸ë˜í”„ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. (ì „ì²´ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
        print(f"   - ì¸ë¬¼ ìˆ˜: {len(graph_data.get('characters', []))}")
        print(f"   - ê´€ê³„ ìˆ˜: {len(graph_data.get('relationships', []))}")
        
        # ì´ë¯¸ì§€ê°€ ìˆëŠ” ì¸ë¬¼ ìˆ˜ ì¶œë ¥
        characters_with_image = sum(1 for char in graph_data.get('characters', []) if char.get('image_src'))
        print(f"   - ì´ë¯¸ì§€ ìˆëŠ” ì¸ë¬¼: {characters_with_image}ëª…")
        
        return graph_data
    except json.JSONDecodeError as e:
        print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ì‘ë‹µ ë‚´ìš©: {response[:1000]}")
        raise
    except Exception as e:
        print(f"âŒ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± ì‹¤íŒ¨: {e}")
        raise

